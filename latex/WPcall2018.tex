\documentclass[DM,lsstdraft,toc,usenatbib]{lsstdoc}

% Package imports go here
\usepackage{amsmath}	% Advanced maths commands
\usepackage{amssymb}
\usepackage{gensymb}  % degree symbol 
\usepackage{natbib}  % bibliography
\usepackage{cprotect} 
% Local commands go here

%% Journal abbreviations
%\bibliographystyle{aasjournal}

\title[Call for LSST Cadence White Papers]{Call for White Papers on \\ LSST Cadence Optimization} 

\author{\v{Z}eljko Ivezi\'{c}, Lynne Jones, Tiago Ribeiro, \\
                 the LSST Project Science Team, \\
                 and  the LSST Science Advisory Committee} 

\setDocRef{Document-XXX}
\date{\today}
\setDocRevision{v0.1}
\setDocStatus{draft}
\setDocAbstract{%
The LSST community is invited to play a key role in the refinement of LSST's Observing Strategy 
by submitting white papers that will describe proposed modifications of the current baseline
survey strategy, including both the main survey and the so-called ``deep drilling fields'' and mini surveys.

While the footprint of the main LSST survey (18,000 sq degrees) is fairly well-defined, the cadence of observations within
this footprint has significant flexibility available. Further, approximately 10\% of the total 
LSST survey time will be available for `deep drilling fields' and mini surveys, and the strategies and time balance for these 
additional surveys are not well defined. We are soliciting white papers to help plan these aspects of the LSST 
survey strategy.

The deadline for these white papers is November 30, 2018.
}

% Change history defined here. Will be inserted into
% correct place with \maketitle
% OLDEST FIRST: VERSION, DATE, DESCRIPTION, OWNER NAME
\setDocChangeRecord{%
\addtohist{1}{2018-06-30}{First released version.}{\v{Z}eljko Ivezi\'{c}}
}

\begin{document}

% Create the title page
% Table of contents will be added automatically if "toc" class option
% is used.
\maketitle


\section{Introduction} 

The Large Synoptic Survey Telescope (LSST) will provide an unprecedented optical 
imaging dataset that will support investigations of our Solar System, Galaxy and Universe, 
across half the sky and over ten years of repeated observation. LSST observations will be
scheduled automatically, with the scheduling algorithm designed to address all science goals 
and maximize observing efficiency for given observing constraints. LSST is constructing a 
flexible scheduling system that can respond to the unexpected and be re-optimized as the survey progresses.. 
It has already been shown through simulated surveys that a basic implementation of LSST's 
10-year observing strategy can meet the basic requirements
described in the LSST Science Requirements Document (\href{http://ls.st/srd}{SRD}\footnote{The LSST Science 
Requirements Document (SRD) is available at \href{http://ls.st/srd}{http://ls.st/srd}})
for the core LSST science goals:
\begin{itemize}
\item constraining dark energy and dark matter,
\item taking an inventory of the Solar System,
\item exploring the transient optical sky, and
\item mapping the Milky Way.
\end{itemize}
An excellent introduction to the baseline survey strategy, expanded background of the primary LSST science 
goals, and concise descriptions of how these goals drive the basic survey strategy and data processing
requirements is provided in the \href{http://ls.st/pif}{LSST Overview paper}\footnote{The LSST Overview 
paper is a living document available at \href{http://ls.st/pif}{http://ls.st/pif}.}.

Nevertheless, the detailed LSST survey strategy is not yet finalized and there
are a number of open optimization questions. Indeed, it is anticipated that the survey strategy 
will continue to be refined and optimized throughout operations. The main purpose of this 
call for white papers is to solicit detailed proposals from communities interested in LSST science
for specific modifications of the current baseline survey strategy, including both the main survey and 
the so-called ``deep drilling fields'' and mini surveys.

\subsection{LSST community and LSST observing strategy}

The LSST community is already playing a key role in the refinement of LSST's observing strategy 
by developing and analyzing metrics for quantifying the success of simulated surveys.
This work is being assembled in an open github community\footnote{
https://github.com/LSSTScienceCollaborations/ObservingStrategy}, 
in the form of a large cross-community survey evaluation paper
titled \href{http://ls.st/9fw}{`Science-Driven Optimization of the LSST Survey Strategy'}\footnote{The first 
version of this community observing strategy evaluation paper was published as arXiv:1708.04058 in August 2017.},
which will be referred to here as the Community Observing Strategy Evaluation Paper (COSEP). 
Chapter 1 and 2 of the COSEP provide a useful overview of the considerations involved in 
modifying the LSST survey strategy, as well as more details of the baseline survey strategy and 
examples of some possible variations on the baseline strategy. 

The COSEP explores the effects of relatively small changes to the LSST survey strategy
on the detailed performance of the anticipated science investigations. The main lessons 
learned from the first version of this paper are: 
\begin{enumerate} 
\item The LSST Project should implement, analyze and optimize the rolling cadence idea
(a non-uniform sampling in time designed to ``compress'' observations for better coverage
of variable phenomena on time scales of a few months, driven by supernovae, asteroids, and
short-timescale stellar variability), and 
\item The LSST Project should execute a systematic effort to further improve the ultimate
LSST survey strategy (e.g., sky coverage optimization, u band depth optimization, special 
surveys, Deep Drilling Fields). 
\end{enumerate} 

Through the end of construction and commissioning, the COSEP will 
remain a living document and the main vehicle for the community to broadly 
communicate to the LSST Project regarding the scientific repercussions of various observing strategies. The LSST Project Scientist will 
periodically synthesize and act on the results presented in this paper, with support from the 
Project Science Team, the Science Advisory Committee and the future Survey Strategy Committee. {\it explain survey strategy committe or remove}

While the COSEP will provide the means to update evaluations of the survey strategy, the white papers solicited in this call are 
intended to provide the chance to propose more significant modifications of the LSST survey strategy. 

\subsection{Motivation for this white paper call}

Guided by the community input summarized in the COSEP and further 
advice from the Science Advisory Committee (SAC), the LSST Construction Project has decided to
solicit detailed technical white papers for specific modifications of the current baseline survey strategy.

As discussed in more detail in Appendix A, analysis to date indicates that the baseline 
survey strategy, while meeting the basic science requirements for the LSST survey, can be meaningfully 
improved\footnote{The baseline survey strategy is described in detail in Sections 1.1 and 2.3 in the COSEP, \href{http://ls.st/o5k}{http://ls.st/o5k}).}.
The LSST \href{http://ls.st/srd}{SRD}
is intentionally vague on survey strategy details because it recognized that science evolves and that the 
initial, by now more than a decade old, survey strategy will have to be re-optimized closer to first 
light. With LSST first light expected in 2020, now is the time to undertake the final pre-commissioning
optimization\footnote{``Optimization'' used here does not imply its strict mathematical meaning. 
We are attempting to create the best survey strategy possible, but this is not a formal optimization 
effort of an objective function in part because the concept of an ``optimized'' survey is difficult to 
define mathematically.} 
of the LSST baseline observing strategy. We seek science-driven input for cadence 
properties such as per-bandpass imaging depth, the sky coverage, temporal coverage, observing
rules, etc., as summarized in Appendix A. Investigations of a limited number of such survey strategy 
modifications are reported in Chapter 2 from the COSEP (and discussed 
in various supplementary materials listed in Appendix C). 


\subsection{General guidelines} 

We solicit detailed proposals for specific modifications of the current baseline survey strategy, including 
both the main survey and the so-called ``deep drilling fields'' and mini surveys. There are no 
specific limitations on what kind of science programs will be considered, but please note that 
the primary four LSST science themes remain the cornerstones of the LSST survey and cannot 
be easily abandoned (the LSST Science Requirements Document states that ``the adopted observing 
strategy will not jeopardize the goals of any of the four main science themes''). In addition, 
LSST's large etendu\'e is a unique resource and science goals which can be carried out with other 
telescopes (e.g., single object investigations) will not be viewed favorably.

Detailed proposals are also solicited for novel ideas, such as TOOs, twilight observing (see \S~\ref{sec:twilight}) and 
(hypothetical\footnote{See \S~\ref{sec:reqinput} for details.}) narrow-bandpass surveys, as well as synergies 
with other major surveys ({\it e.g.}, WFIRST, Euclid). 

At this time we are not soliciting proposals to optimize observations during the commissioning period.
A call for commissioning proposals will be issued once the start date of commissioning is known with adequate accuracy (1-2 months). 

Technical constraints imposed by the system and observing conditions are summarized in 
Appendix B. In cases that require more detail, or in case of specific questions not addressed in this 
document, please start a discussion at \href{http://community.lsst.org}{community.lsst.org}\footnote{\url{https://community.lsst.org/c/sci} XX finish complete link}.

The LSST Science Requirements Document states that ``the adopted baseline design assumes a 
nominal 10-year duration with about 90\% of the observing time allocated for the main LSST survey.'',
and further clarifies that ``The remaining 10\% of observing time will be used to obtain improved 
coverage of parameter space\dots''. While the detailed time allocation will eventually depend on currently unknown system
performance parameters, it is unlikely that the goals of the main survey could be met with a time allocation
significantly below 80\%. In other words, it is plausible that the time allocated to programs other
than the main survey could significantly exceed 10\% (perhaps by as much as a factor of two), but 
no firm commitments beyond this statement of plausibility can be made at this time. 

The data from any given specialized survey will be treated in exactly the same way as all LSST 
data: there is no special proprietary access for the proposers. Indeed, the final set of the so-called
deep-drilling fields and other mini-surveys may be based on an amalgam of ideas from different 
white papers; there will be no sense in which a given proposal must be accepted or rejected as-is.  


\subsection{Review process and timeline}

The deadline for submitting white papers is November 29, 2018. For submission instructions, 
please see the next section. The input from the submitted white papers will be used to design multiple
options in observing strategies and generate quantitative assessments to be used for survey strategy optimization.
These multiple strategies will address varying science drivers and will form a ``menu'' of possible survey strategies (e.g., a main 
survey with 18,000 deg$^2$ of sky coverage vs. sky coverage of 23,000 deg$^2$ to a
somewhat shallower depth). The performance evaluation criteria submitted as part of the white paper proposals
will be used to generate quantitative assessments to compare these strategies. 

Soon after the November 2018 submission deadline, members of the LSST Science Advisory Committee (SAC), 
with technical support from the Project\footnote{The Project will establish a Survey 
Strategy Committee to evaluate competing survey strategy proposals and to propose a general survey 
strategy for commissioning and operation. The committee will be comprised of both project and 
non-project personnel, with the SAC making recommendations for committee membership.}, 
will triage white papers and decide which meet the criteria of scientific excellence and 
technical feasibility for further analysis (including suggestions for combining 
proposals into single programs, and giving suggestions for maturation of the current notional 
extragalactic observing strategy). 

We anticipate that the resulting list of observing strategies that will be simulated and analyzed 
(the ``menu'' above) will be available by April 2019. Simulated survey outputs and Metric Analysis 
Framework (MAF\footnote{https://sims-maf.lsst.io}) analyses will become available by the end 
of 2019. 

An advisory report on these survey strategies will be prepared for the LSST SAC during early 2020, 
in a close collaboration between the Project and the Observing Strategy Github community and 
LSST Science Collaborations. The SAC will in turn advise the project on the specific survey strategy 
to be used at the start of LSST operations. In developing their recommendations to the Director, the SAC will be guided by selection 
criteria set by the Project Science Team ({\it e.g.}, restrictions based on technical criteria,
such as those discussed in Appendix B). The Director can further consult with the Project Science 
Team about the SAC survey strategy recommendations. A baseline simulation that reproduces the
adopted strategy, and its detailed performance analysis, will be published in 2021. 
The start of LSST operations is anticipated in 2022.

An overall aim of the Project and all stakeholders is to make this process transparent and to base 
all decisions on quantitative input and pre-defined criteria to the maximum extent possible. 
The Project will organize a dedicated session about this call for white papers, to further clarify 
details, exchange ideas, discuss simulated surveys, and coordinate teams that plan to submit white papers,
at the LSST 2018 All-hands meeting (Tucson, Aug 13-17). 


\section{White paper submission guidelines} 


\subsection{Who can submit a white paper?} 

All members of the scientific community interested in LSST science can submit a white paper. 
We reiterate that the data from any given specialized survey will be treated exactly the same 
way as all LSST data: the proposers will have no proprietary access to it. There will be no 
formal ``acceptance'' of proposals; with the overall ranking priority advice provided to the 
Project by the Science Advisory Committee, the Project Team will implement a number of
different strategies that will be used as quantitative input (``a menu of options'') by the 
Science Advisory Committee when recommending strategy for the initial phase of LSST survey. 


\subsection{Requested input \label{sec:reqinput}}

The current list of surveys, for which quantitative optimization input is requested are:
\begin{itemize}
\item the main Wide-Fast-Deep (WFD) survey,
\item the Deep Drilling (DD) fields,
\item Northern Ecliptic Spur (NES) mini-survey, 
\item Galactic Plane (GP) mini-survey, and
\item South Celestial Pole (SCP) mini-survey.
\end{itemize}

We seek science-driven input for survey strategy questions such as optimal visit exposure time,
co-added per-bandpass imaging depth, the sky coverage, temporal coverage, observing
rules, etc.; for a detailed discussion, please see Appendix A. For some special programs, 
e.g., target-of-opportunity (ToO) observations, it is important that reasonable
information is provided to enable proper simulations to be conducted, as well as an estimation
of total observing time allocation. The TeX submission template described in \S~\ref{sec:textemplate} 
provides further submission details. 

In addition to existing surveys listed above, we also seek input on new mini-survey ideas 
to replace and/or enhance the current programs, including special ToO programs. We also 
solicit novel ideas, such as twilight observing (see \S~\ref{sec:twilight}) 
and (hypothetical) narrow-bandpass surveys\footnote{This idea is somewhat hypothetical 
because it implies that additional hardware would be procured. For more details and 
discussion of science drivers, please see the \href{http://ls.st/741}{Narrow band LSST filters} white paper at \url{http://ls.st/741}}, 
as well as observing synergies with other major surveys (e.g., WFIRST, Euclid). 

It would greatly help if each white paper could be assigned to one of the following
categories:  
\begin{itemize} 
\item a specific observing strategy to enable specific time domain science, 
	that is relatively agnostic to pointing (e.g., a science case enabled 
	by relatively deep precise time-resolved multi-color photometry). 
\item a specific pointing(s) that is (relatively) agnostic of the detailed observing 
	strategy (e.g., a science case enabled by very deep precise multi-color 
	photometry) 
\item an integrated program with science that hinges on the pointing/detailed 
	observing strategy combination (e.g., search for variable stars in the 
	LMC/SMC). 
\end{itemize}  
If a specific white paper does not fit any of these categories, please state so.

We reiterate that that the observing time allocated to {\bf all} the mini-surveys 
(including DD) is ``about'' 10\%, and is unlikely to exceed 20\% of the total available
observing time. We note that implementation details for mini-surveys and DD fields 
are coupled at some level to the main survey: more time for the former means less 
for the latter, and some of the design decisions for the latter affect the science
case for the former.  For example, some rolling cadence strategies for the main survey  
may allow some variable and transient science to happen that would otherwise be the 
focus of a deep drilling field, and changes in the main survey footprint will affect the 
definition of a Galactic Plane survey. 


\subsection{TeX template for submission \label{sec:textemplate}} 

Each proposed modification of the survey strategy must contain a Scientific Motivation, Technical Description, and Performance Evaluation section, instructions for which are expanded in the white paper submission template. The Scientific Motivation section is intended to explain why this survey strategy modification is important and what can be learned if the proposed observations were obtained. The Technical Description section details what observations are being requested and should provide enough detail to enable proper simulations to be created, as well as additional information that can help in the process of combining similar but separate survey strategy modification requests. The Performance Evaluation section must contain methods to evaluate the effectiveness of the survey strategy modifications, particularly in light of the potential effect of survey strategy changes proposed in other white papers. It is unlikely that any given proposal will be able to accomplished in its ``ideal'' form, thus metrics (along with threshold values for these figures of merit) to evaluate the science performance of non-ideal simulations are crucial. 

The submission template and an example of the submission, with instructions about
all the required information, can be found in the git repository hosted at \href{https://github.com/lsst-pst/survey_strategy_wp}{lsst-pst/survey\_strategy\_wp}\footnote{\url{https://github.com/lsst-pst/survey_strategy_wp}}.
The submission process includes the following steps: 
%
\begin{enumerate}
\item Fork the repository using your (the PI's, or a selected collaborator's)  Github account.
\item Clone the forked repository to your local machine.
\item Create a directory with the PI name as LASTNAME\_FIRSTNAME\_NUMBER,
where NUMBER is a counter for multiple proposals submitted by the same person (or the case
of two people with the same name). 
\item Copy the template to the directory created in the last step.
\item Fill the latex template file with the proposal information. It is possible to make intermediate 
          commits to keep track of the changes to the proposal and share it with collaborators.
\item Once the proposal is ready, make a Pull Request (PR) to the master branch of the main repository. 
\item A team member will accept your PR, or contact you in case of problems. 
\end{enumerate}

For additional help or questions, please ask on \href{https://community.lsst.org/c/sci}{LSST Community}\footnote{\url{http://community.lsst.org/c/sci}}. 


\section{Proposal ranking criteria} 

The ultimate LSST observing strategy will aim to deliver a cutting-edge data set to enable
the four LSST's cornerstone scientific programs, while at the same time maximizing the 
science possible with specialized observing using about 10\% of the total observing time. 

We anticipate that the adopted observing strategy will be based on an amalgam of ideas from 
different white papers; therefore, there will be no formal ``acceptance'' of proposals. The
overall ranking priority advice provided to the Project by the Science Advisory Committee 
will be based on the following considerations\footnote{The PST is expected to review these ranking criteria before the call for white papers is published.}: 
\begin{itemize}
\item {\bf Science} Importance and robustness of proposed science program, including 
           its match to the unique abilities of the LSST system, and its consistency with the 
           main four LSST science themes. 
\item {\bf Versatility} The ability of proposed dataset to maximally enable LSST's diverse science objectives. 
          Functionally, this means (for programs with large area footprints) that Solar System and Milky Way science will be prioritized for pointing selection,
          with Time Domain science likely driving the temporal sampling window, and extragalactic science driving 
          the sky coverage and co-added depth. Programs proposing datasets that are of interest to other astronomical 
          facilities (e.g., observable by other flagship facilities on ground and in space) also demonstrate good versatility.
\item {\bf Feasibility} Programs should be feasible from the hardware and software point of view (see Appendix B),
         specifically including any special data processing required.
\item {\bf Time requested} The amount of time (including overheads) required should be justified by 
        the associated science. 
%\item {\bf Efficiency} Observing efficiency (including the system safety considerations).  Deep-drilling field 
%         programs should be feasible from the hardware and software point of view (see Appendix B) and should 
%          come in under ``rule of thumb'' amount of total observing time ($<$1\%, e.g. 250-300 hours of time,
%          including overhead). 
\end{itemize} 

As always, the science program properties such as importance and robustness are open
to interpretation. It is inevitable that some science drivers will be in conflict, and even
observing efficiency may not be defined in an absolute sense. The Project and the Science Advisory 
Committee will strive to make the proposal ranking process transparent to the maximum extent possible. 


\vskip 0.2in 
{\it Acknowledgments:} this document has greatly benefited from discussions between 
the LSST Project Science Team, the LSST Science Advisory Committee and Kem Cook, 
Phil Marshall, Steve Ridgway, Daniel Rothchild, Peter Yoachim and numerous other members 
of the LSST Science Collaborations. 

\newpage
\appendix
\section{Examples of open survey strategy optimization questions} 

The quantitative optimization of the LSST observing strategy requires many 
detailed decisions to be made, often with only an indirect science justification,
or with conflicting science drivers.  The current most significant open questions and associated 
tradeoffs are listed below for the main survey and each mini survey. White papers are specifically 
encouraged to address these questions.


\subsection{The main Wide-Fast-Deep survey} 

The baseline survey strategy optimizes the amount of sky covered in any given night (subject to 
the constraint of observing at airmass less than 1.5 and gathering pairs of visits in each night), 
and allows the entire sky visible at any time of the year to be covered in about three nights. 
The basic strategy is designed to give roughly uniform coverage at any given time, and to reach
the survey goals for measuring stellar parallax and proper motion, and the number of visits per 
field (825 visits, summed over the six filters). In the baseline implementation, the main survey 
covers about 18,000 deg$^2$ of high Galactic latitude sky, and spends about 85\% of the available 
observing time. 

Open questions and optimization options associated with the main survey are as follows: 
\begin{itemize}
\item With the current declination boundaries at Dec = $-65^\circ$ and Dec = $+5^\circ$,
the main survey area includes about 18,000 deg$^\circ$ (without the Galactic plane 
confusion zone, see \ref{sec:GP}). These boundaries were set to optimize the number of
detected galaxies and galaxies useful for cosmological studies. These galaxy counts 
stay within 5-10\% of the current baseline values even with a much larger survey area. 
For example, Section 2.4 in the Observing Strategy white paper describes a simulated survey
that covers 27,400 deg$^2$ to about 0.15 mag shallower co-added depth than in the baseline 
survey (the airmass limit is relaxed to 1.5 and declination boundaries are at Dec = $-78^\circ$ 
and Dec = $+18^\circ$, with the mean number of visits per field about 20\% smaller that
in baseline survey). This tradeoff between the sky coverage and co-added depth is still
open to optimization and it is important to receive science-driven optimization arguments
from all science programs. 
\item The observing time allocation per band (number of visits per filter) listed in the Science Requirements Document
(Table 24) is given only as an illustration. Further optimization of this allocation for the main 
survey, and different fractional allocations for mini surveys, are likely possible. 
\item A ``rolling cadence'' (as opposed to uniform temporal sampling) can provide enhanced
sampling rates over a part of the survey for a designated time, at the
cost of reduced sampling rate the rest of the time (while maintaining the nominal total 
visit counts). While it is likely that science programs such as supernovae, asteroids, and
short-timescale stellar variability would benefit from rolling cadence, detailed cadence
parameters have not been optimized yet ({\it e.g.}, how much of the 
survey area to ``roll'' at once and how long to ``roll'' for, or whether to ``roll'' in RA or Dec). 
\item The current baseline survey strategy obtains two visits per night (within 15-60 minutes) in 
order to enable easy linking of asteroid detections, and robust identification of rapid 
photometric transients. Whether the two visits on the same night should be obtained 
in the same filter or in different filters has not been decided yet (e.g., in the context
of photometric transients, same filters would provide a more accurate measurement
of the brightness change, while different filters would provide a color constraint). 
\item The current strategy for the main survey which obtains two visits per night could be 
modified to obtain a single visit, or more than two visits, per night. 
\item The current baseline survey strategy assumes that a visit is composed of two 15-second
exposures, the so-called snaps. While snaps enable search for very rapid variability,
and help with cosmic ray rejection, there are compelling technical arguments to abandon
them, with observing efficiency being the main argument. Arguments for retaining the
snaps would be very useful in further optimization of the main survey strategy. 
\end{itemize}
White papers addressing all or some of these optimization efforts are strongly encouraged.


\subsection{``Deep Drilling'' fields} 

The Deep Drilling (DD) fields are single pointings that are observed in extended sequences. 
In the first call for white papers in 2011 on survey strategy optimization, the Project received 
8 white papers from the community\footnote{These white papers are available from 
https://project.lsst.org/content/whitepapers32012}. These proposals often include certain 
filter combinations to ensure that near-simultaneous color information is available for 
variable and transient objects. While science programs suggested in DD proposals are ideally well 
matched to the size of LSST field of view (9.6 deg$^2$), it is plausible that some
programs may require several fields. 

Four of the LSST DD fields have been selected and announced (Elias S1, 
XMM-LSS, Extended Chandra Deep Field-South, and COSMOS). It is guaranteed that they 
will be observed with deeper coverage and more frequent temporal sampling than the main 
survey fields, but details are still open. It is expected that there will be more DD fields 
selected for the final survey (a plausible but not prescriptive range is 5-10). 

The observing sequences for these DD fields are not well determined. The current baseline
cadence includes sequences of $grizy$ observations during bright time, and sequences of $u$ 
band observations during dark time. The large number of filter changes in the bright time sequences
are inefficient and the large gap in multi-color sampling during dark time is likely problematic 
for variable and transient characterization. White papers addressing improved cadences for DD 
sequences are desirable.


\subsection{Galactic plane survey \label{sec:GP}}

The baseline main survey excludes observations at low Galactic latitudes, where the high 
stellar density leads to a confusion limit at much brighter magnitudes than those attained 
at high Galactic latitudes. Assuming median seeing, this confusion limit corresponds to a
source density of about 1-2 million per deg$^2$. The current boundary of this ``Galactic
confusion zone'' starts at $|b|=10^\circ$ towards $l=0^\circ$ and linearly drops to $b=0^\circ$
at $l=90^\circ$ and $l=270^\circ$. Along this boundary, the confusion limit is reached at a
depth of $i \sim 26$; therefore, the useful coadded depth is at least 1-2 magnitudes 
shallower than for the main survey. Within this boundary, the fraction of galaxies is only
a few percent and an assumption that all sources are stars works well. For example, 
DECAPS survey generated a catalog with 2 billion sources in the Southern Galactic Plane
to a depth of about $r=23$ (with seeing around 1 arcsecond; Schlafly et al. 2018, 
arXiv:1710.01309). 

As guidance, stellar count simulations with the TRILEGAL code (Girardi et al. 2005, 
arXiv:astro-ph/050404) show that to the depth of $r=27.5$ there are about 2 billion
stars in the main survey area, with another 5 billion stars in the Galactic confusion 
zone. Of the latter, about 3 billion are brighter than $r=24.5$.   XXX ZI: this is based
on Galfast simulations and will be updated with TRILEGAL results. 

The current strawman implementation of the Galactic confusion zone coverage allocates 
30 observations in each of the six filters. Detailed optimization of this strategy has not 
been done yet. In particular, science-driven input is needed for both ``static science''
programs (e.g., The Blanco DECam Bulge Survey, BDBS Collaboration; DECAPS survey) 
and  time domain surveys (e.g., Gould 2013, arXiv:1304.3455). 

The footprint in the current baseline survey strategy extends to far north along the Galactic
plane, to the region that can only be observed at relatively large airmass from the LSST
site at Cerro Pach\'on ($X>1.4$ at Dec=$+15^\circ$). Originally, this extension was designed 
to extend longitudinal coverage of the Galactic plane with Galactic structure studies in mind. 
With the advent of other surveys (e.g., Pan-STARRS and DECAPS), the reasons for obtaining 
these less efficient observations (due to unavoidable high airmass) are less compelling. 
Unless a strong case is made in submitted white papers, the Project is likely to limit the 
coverage of the Galactic plane to Dec=$<+5^\circ$. 


\subsection{Southern Celestial pole mini survey}

Due to its southern declination limit ($Dec > -65^\circ$), the main survey misses large fraction
of both the Magellanic Clouds. To allow coverage of the Large and Small Magellanic Clouds, 
baseline survey strategy uses relaxed limits on airmass and seeing for the $\sim$2,000 deg$^2$ region 
around the South Celestial Pole, but with fewer observations than for the main survey. 

Detailed optimization of this strategy has not been done yet. Given recent informative observations 
obtained by the SMASH survey (Nidever et al. 2017, arXiv:1701.00502), as well as calibration 
and legacy aspects of this mini survey, a white paper with more detailed cadence prescriptions
(e.g., is it necessary to extend the coverage all the way to the South Celestial pole?) would greatly 
inform further cadence optimization and help retain this mini survey. 


\subsection{Northern Ecliptic spur mini survey}

The main survey footprint provides most of LSST's power for detecting Near Earth Objects (NEO) and 
Kuiper Belt Objects (KBOs) and naturally incorporates the southern half of the ecliptic within its 
18,000 deg$^2$ sky area. Additional coverage of a crescent reaching to +10 degrees of the Northern ecliptic 
plane would sample the full azimuthal distribution of TNOs, crucial for understanding the different 
dynamical families in which they fall, and would improve the light curve sampling and completeness
of asteroid populations in the inner Solar System. The baseline survey strategy covers this region using the 
$griz$ filters only, along with more relaxed limits on airmass and seeing. A more detailed 
and robust science-driven justification addressing both outer Solar System (e.g., TNOs) and inner Solar
System (e.g., main-belt and NEO asteroids) populations is needed to retain and improve this mini survey. 


\subsection{Twilight survey \label{sec:twilight}} 

LSST's short read-out time (2 sec) enables efficient taking of short-exposure images during twilight time 
that would otherwise go unused. Science drivers and technical details are discussed in Section 10.3 in the 
Observing Strategy white paper (arXiv:1708.04058); the former include a bright star survey for Galactic
science, obtaining light curves for nearby supernovae, and observations of near-Earth asteroids towards
so-called ``sweet spots'' (on the Ecliptic, at Solar elongations of $\sim60^\circ$). This cadence has not 
been simulated yet because sufficiently detailed and accurate sky brightness model, that includes twilight 
effects, has become available only recently (Yoachim et al. 2016, Proc. SPIE, 9910-48, 99101A-1). 

The Project plans to simulate twilight observing in the next round of simulations (scheduled for late 2018). 
Assuming exposure times of 1 second (the stretch goal from the LSST Science Requirements Document, 
which is already met and corresponds to the Camera baseline requirement), the saturation limit would 
improve by about 3 mag relative to 15-sec exposures; in the $r$ band from about $r=16$ to $r=13$,
with about 1.5 mag loss of limiting depth. The improvement in dynamic range of 1.5 mag would gradually
diminish and eventually dynamic range would vanish as the sky brightness increases. About 20-30 minutes
of additional observing time could be utilized during twilight before dynamic brightness range becomes
too small. Assuming 7-sec visits (1 sec exposure + 1 sec for shutter + 5 sec for read and slew), about 
2,000 deg$^2$ of sky could be imaged in 25 minutes (assuming no filter changes). Alternatively, over 
350 exposures (1 sec + 1 sec + 2 sec) of the same field could be obtained instead.  Detailed strategies
should consider limitations on the number of filter changes (see \S~\ref{sec:HW}). 
White papers addressing the science justification and strategies for using twilight time are desired.

The shortest exposure stretch goal in the Camera baseline requirements is set to 0.1 sec. Science-driven
studies that would advocate pursuing this goal would be a welcome contribution to further system
optimization; twilight observing would especially benefit from shorter exposures. 
 

\section{Constraints on survey strategy imposed by the LSST system} 

\subsection{Hardware constraints \label{sec:HW}}

Several hard constraints prevent observations in certain directions. The telescope altitude limit
prevents observations at altitudes below 20$^\circ$.  As a consequence of alt-az mount, there
is also a zenith exclusion zone with a radius of 3.5$^\circ$. 

LSST telescope mount uses direct drive motors and there should not be any mechanical limits 
on slewing from the mount.  However, there are observing efficiency considerations: the minimum
slew time (as soon as the telescope moves at all) is 3 seconds, due to readout (2s) plus settle time requirements (1s). 
Otherwise, the slew time depends on slew distance. Approximately\footnote{Precise values can be obtained using
method ``get\_approximate\_slewdelay'' from ts.observatory.model}, in the azimuth direction, 
\begin{eqnarray}
             t_{slew}^{Az} = 0.66 \, {\rm sec/deg} * \delta Az ({\rm deg}) + C^{Az} \\
             t_{slew}^{Az} {\rm min} = 3\, {\rm sec}
\end{eqnarray} 
where $C^{Az} = -2$ sec (this is negative because of dome crawl; however, the minimum
slew time is still 3 seconds due to readout and telescope settle time). For slewing in altitude
\begin{equation}
             t_{slew}^{Alt} = 0.57 \, {\rm sec/deg} * \delta Alt ({\rm deg}) + C^{Alt} ,  
\end{equation} 
where $C^{Alt} = 3$ sec for slews below 9$^\circ$ and $C^{Alt} = 37$ sec for longer slews (because 
of the need to recompute optics corrections for slews larger than 9 degrees in altitude). 
The dome is assumed to crawl in the azimuth direction, but not in altitude. 
In the baseline simulated survey, about 2\% of slews move
in altitude more than 9$^\circ$. 

The shortest exposure time is 1 second, with the shortest exposure stretch goal in the Camera 
baseline requirements set to 0.1 sec. For exposures shorter than 
about 10 sec, the seeing due to atmospheric turbulence may be harder to characterize (more
irregular) than for longer exposures, and moving objects may trail in long exposures (for more
details see Section 5.1.4 in Jones et al. 2018; Icarus 303, 181). Short exposures will have a low
observing efficiency due to finite read-out time (2 sec) and the shutter open/close time (1 sec). 

There are important constraints on the filter exchange strategy. As the system is not yet completely 
built and characterized, the following represents current understanding, based on the design and on 
engineering judgement. As such, some of the details should be considered preliminary and subject 
to change. Expanded ranges could be possible if there are strong scientific motivations along with
sufficient resources during operations.
\begin{itemize}
\item The filter change mechanism is designed to undergo a total of 100,000 changes over its lifetime 
	(about 27 changes per day of the survey, 17 during the night and 10 for daylight calibrations). 
\item Each filter is designed to support up to 30,000 changes over its lifetime.
\item A maintenance cycle is anticipated, and this would nominally occur after 10,000 changes or 
          one year, whichever is reached first. 
\item During a given observing night, the system could support as many changes involving the 5 filters 
          loaded in the carousel as desired, without any practical limitation beyond the two-minute change 
          interval (which consists of 90 seconds for the exchange plus up to 30 seconds to put the camera
          into the required orientation). 
\item Filter loader operations (swapping a filter in the carousel) will be done during daytime. The system 
          is designed for 3000 loads over its lifetime. 
\item The currently implemented filter-swap strategy is to replace one of the $z$ or $y$ 
	by the $u$ band at the start of dark time, when the lunar phase reaches $20\%$. The 
	process is reversed at the end of dark time when the lunar phase is above the same threshold. 	
\end{itemize} 


\subsection{Software constraints} 

The LSST Science Requirements Document specifies that ``As a general principle, the measurement errors
for fundamental quantities, such as astrometry, photometry and image size, should not be dominated by 
algorithmic performance.''. Data products that LSST will produce are described in LSST Data Products
Definition Document (ls.st/dpdd) and more algorithmic detail is provided in LSST Data Management 
Science Pipelines Design document (ls.st/ldm-151). 

The Project will not take formal responsibility for specialized data reduction algorithms 
needed to process data, including that taken in ``non-standard'' modes; detailed discussion is 
available in Data Management and LSST Special Programs document (ls.st/dmtn-065) and should
be perused when proposing non-standard observing sequences. In addition, we strongly recommend to 
consult Sections 5 and 6 in the \href{http://ls.st/dpdd}{LSST Data Products Definition Document}. If a proposed dataset will 
require special processing, a plan to obtain necessary software and compute resources must be 
provided in the white paper proposal.

There is an additional caveat regarding crowded field processing (see also Section \ref{sec:GP}). 
A fraction of LSST imaging will cover areas of high object (mostly stellar) density, such as the 
Galactic plane, the Large and Small Magellanic Clouds, and a number of globular clusters (among 
others). LSST image processing and measurement software, although primarily designed to operate 
in non-crowded regions, is expected to perform well in areas of crowding. The current LSST applications 
development plan envisions making the deblender aware of Galactic longitude and latitude, and 
permitting it to use that information as a prior when deciding how to deblend objects. While not 
guaranteed to reach the accuracy or completeness of purpose-built crowded field photometry codes, 
we expect this approach will yield acceptable results even in areas of moderately high crowding.

The above discussion only pertains to processing of direct images. Crowding is not expected to 
significantly impact the quality of data products derived from difference images (i.e., Prompt 
products).


\subsection{Observing efficiency constraints} 

The LSST Science Requirements Document  ``...assumes a nominal 10-year duration with about 90\% 
of the observing time allocated for the main LSST survey.'', and thus 10\% of observing time is left for 
all other programs. However, if the system will perform better than expected, or if science priorities 
will change over time, it is conceivable that 90\% could be modified and become as low as perhaps 80\%, 
with the observing time for other programs thus doubled. At this time, details are TBD but the Project
is developing flexible scheduling procedures to enable such modifications. 

We note that the uncertainty in our system performance estimates due to weather and solar activity is about 10\%.
In addition, the system has not been built yet and many hardware performance parameters are
still taken at their design values.  

Sustained observing, such as the main survey, with exposures much shorter than standard visits will result
in diminished observing efficiency. Given total visit exposure time $t_{vis}$ (30 sec for standard
visits), with two exposures/readouts (snaps) per visit, and assuming a slew and settle time of 5 sec 
(also including the second readout), the observing efficiency can be computed as 
\begin{equation}
     \epsilon = \left( {t_{vis} \over t_{vis} + 9 \, \mathrm{sec}}\right).
\end{equation}
To maintain efficiency losses below $\sim$30\% (i.e., at least below the limit set by the weather patterns),
and to minimize the read noise impact, $t_{vis} > 20$ seconds is required for sustained observing. 

Variations in exposure time for the main survey affect not only the limiting depth, but also the total number of 
acquired visits and revisit time because the total observing time is finite. For more detailed 
discussion of these tradeoffs, please peruse Section 2.2.2 in the Overview paper. 

The number of filter changes and size of slews also affects efficiency. 

\subsection{Limiting depth and uncertainty estimates}  

Methods for estimating individual image depth ($5\sigma$ point source magnitude limits) for a given exposure time and other observing parameters
is discussed in detail in Section 3.2 in the LSST Overview paper (see \ref{sec:pubs}). Tradeoffs between 
exposure time per visit, single-visit depth, the mean revisit time, and the total number of visits,
as well as justification for the adopted standard exposure time of 30 sec, are discussed in Section 
2.2 from the same paper. The improvement in measurement uncertainties as the surveys progresses,
as a function of time $t$, can be approximately summarized as follows. 

The co-added depth (the 5$\sigma$ depth for point sources), $m_5^{\rm co-add}$, scales 
with time as (see eq.~6 in the overview paper)  
\begin{equation} 
         m_5^{\rm co-add}  = m_5^{\rm co-add, Final}  + 1.25 \, \log_{10}\left({t \over 10 \, {\rm yrs}}\right) 
\end{equation} 
where $m_5^{\rm co-add, Final}$ is the target depth achieved with 10-year survey. With
airmass and other losses taken into account, $m_5^{\rm co-add, Final}=27.2$ for the $r$ band
in the baseline simulated survey. 

The photometric errors (inverse signal-to-noise ratio) at the faint limit of the so-called 
``gold'' galaxy sample (4 billion galaxies with $i<25.3$ which will be used for cosmological
programs, see Section 3.7.2 in the LSST Science Book), is computed from (see eq. 5 and Table 1 
in the overview paper):
\begin{equation} 
                \sigma_{i=25} = 0.04 \, \left({t \over 10 \, {\rm yrs}}\right)^{-1/2} {\rm mag.}
\end{equation}

The volume of the 5-dimensional color space per source with $i=25$,  which controls the ability 
to classify sources using colors (including photometric redshift estimates for galaxies and star/quasar
separation, for example) is computed assuming uncorrelated color errors, as proportional
to $\sigma^5_{i=25}$, and normalized by the value corresponding to 10-year survey. 

The trigonometric parallax accuracy for a point source with $r$=24 (see section 3.3.3 in the 
overview paper) scales with time as 
\begin{equation}
        \sigma_\pi = 3.0 \,  \left({t \over 10 \, {\rm yrs}}\right)^{-1/2}  \,\,  {\rm mas.} 
\end{equation}

The proper motion accuracy for a point source with $r$=24 (see section 3.2.3 in the overview paper)
scales with time as 
\begin{equation}
        \sigma_\mu = 1.0 \,  \left({t \over 10 \, {\rm yrs}}\right)^{-3/2}   \,\, {\rm mas/yr.} 
\end{equation}
Note the very strong dependence of  $\sigma_\mu$ on time ($t^{-1/2}$ comes from the
increase in the square root of the number of visits, analogously to $\sigma_\pi$, and 
an additional $t^{-1}$ from the linear increase in temporal baseline).  In both expressions,
the number of visits is assumed proportional to time, with a value of 825 corresponding to the 
main deep-wide-fast 10-year survey. 

The behavior of these quantities as a function of time is summarized in Table 3. While 
the co-added depth and $\sigma$($i$=25) rapidly improve during the first few years, 
several important quantities continue to show marked improvement between the survey 
years 8 and 10: most notably, the color volume per source for faint sources ($i=25$) 
shrinks by a factor of 1.7.  Substantial improvement is also seen for proper motions, 
with errors larger by 40\%, after 8 years than at the end of the 10-year survey.  

\begin{table}
\caption{Various science metrics as functions of survey duration.}
\begin{tabular}{|l|r|r|r|r|r|r|}
\hline     
          Quantity                          &     Year 1   &    Y3  &     Y5  &     Y8   &     Year 10   \\
\hline  
    $r_5$ coadd$^a$                   &       26.0    &      26.5   &      26.8    &      27.1    &          27.2     \\
    $\sigma$($i$=25)$^b$         &     0.12    &     0.07    &      0.06    &    0.05      &        0.04        \\     
    color vol.$^c$                        &       316     &       20     &        6      &    1.7        &           1       \\
     \# of visits$^d$                    &          83     &     248     &      412     &    660      &          825      \\  
    $\sigma_\pi$ ($r$=24)$^e$   &        9.5     &      5.5     &        4.2    &     3.3       &          3.0      \\ 
    $\sigma_\mu$ ($r$=24) $^f$  &  32   &      6.1    &     2.8   &     1.4   &     1.0     \\
\hline                         
\end{tabular}
\\ \vskip 0.05in
$^a$ The co-added depth in the $r$ band (AB, 5$\sigma$; point sources).  \\
$^b$ The photometric error for a point source with $i=25$. \\
$^c$ The volume of the 5-dimensional color space, normalized by the final value. \\
$^d$ The number of visits per sky position (summed over all bands). \\
$^e$ The trigonometric parallax accuracy for a point source with $r$=24 (milliarcsec). \\ 
$^f$  The proper motion accuracy for a point source with $r$=24 (milliarcsec/yr).  \\
%\vskip 0.2in          
\end{table}



\section{Supplementary materials} 
\label{append:supplemental}

\subsection{Useful publications and websites \label{sec:pubs}}

{\it Note that various websites and documents references here are still in development (if not an official LSST change control document).}

The \href{https://www.lsst.org/content/lsst-science-drivers-reference-design-and-anticipated-data-products}{LSST Overview paper} provides a short summary of the four primary science drivers, as well as the expected performance of LSST in terms of throughputs, and calibration. 
It also discusses high-level survey constraints and tradeoffs.  Available as \url{http://ls.st/pif}

The \href{https://github.com/LSSTScienceCollaborations/ObservingStrategy}{Observing Strategy White Paper}  (OSWP) is a community-driven paper describing a wide variety of science cases and their implications for survey strategy. This paper is primarily aimed at helping define the main (90\%) WideFastDeep survey. Available as \url{http://ls.st/3y1}

The \href{http:/ls.st/srd}{LSST Science Requirements Document} (SRD) describes the official requirements for LSST science deliverables. Section 3.4 is the most relevant for survey strategy, although other sections are relevant for telescope and camera performance such as throughputs and readout time. Available as \url{http://ls.st/srd}

The \href{http://ls.st/dpdd}{LSST Data Products Definition Document} (DPDD) describes the data products that LSST will provide, with some high-level background on how they will be produced. If you want to know what will be contained in various catalogs, this is a good place to look. Available as \url{http://ls.st/dpdd}

The \href{http://ls.st/ldm-151}{LSST Data Management Science Pipelines Design} (LDM-151) document describes the LSST data management processing pipelines. This provides details of how and when images will be processed and catalogs will be generated, including information on the algorithms used in each processing stage. If you want to know more about the details of a value in an output catalog and how it will be calculated, this is the place to look. Available as \url{http://ls.st/ldm-151}

%The \href{http://ls.st/lse-61}{LSST Data Management System Requirements} (DMSR) document details the official requirements for LSST's data management processing. This is a higher level of detail than the DPDD on the characteristics and specifications of individual data products but does not describe how these data products are created. \url{http://ls.st/lse-61}

Documentation about OpSim (SOCS and Scheduler), including a high-level overview and description of scheduling options, is available at \url{http://sims-opsim.lsst.io}.

Documentation about MAF, including a high-level overview and descriptions of current standard metric analyses, is available at \url{http://sims-maf.lsst.io}. 

The \href{https://github.com/lsst-pst/survey_strategy/blob/master/db/baseline-doc/baseline.pdf}{baseline simulated survey} document describes the new features enabled in Opsim v4, as well as characteristics of the updated baseline simulated survey. 

The outputs of MAF analyses for the new baseline survey, as well as runs demonstrating potential options for mini surveys and Deep 
Drilling fields (a subset of the runs described in Chapter 2 of the OSWP) are available \href{http://astro-lsst-01.astro.washington.edu:8080}{online} at \url{http://astro-lsst-01.astro.washington.edu:8080}. 

A short description of the current Deep Drilling fields and links to further materials (including white papers submitted in response to the 2011 call for input on the DD strategy) are available on the LSST website at \href{https://www.lsst.org/scientists/survey-design/ddf}{http://ls.st/57q}. Additional posts on LSST Community can be found by searching for \href{https://community.lsst.org/search?q=deep%20drilling}{`deep drilling'}. 

Additional information is available in the following presentations:
\begin{itemize}
\item ``Overview of the LSST Observing Strategy'' (Nov 16, 2015): \url{http://ls.st/4yh}
\item ``The LSST Deep-Drilling Fields: White Papers and Science Council Selected Fields'' (Aug 15, 2016): \url{http://ls.st/wzy}
\item ``Observing Strategy White Paper Status Report'' (Mar 5, 2017): \url{http://ls.st/zj2}
\item ``LSST Plans for Cadence Optimization'' (May 30, 2017): \url{http://ls.st/ot2}
\item ``Special Programs'' (Aug 15, 2017): \url{http://ls.st/10o}
\end{itemize}.


\subsection{Communication about the LSST survey strategy} 

The Project Scientist (\v{Z}eljko Ivezi\'{c}, e-mail: ivezic at astro.washington.edu) is formally responsible for survey strategy optimization efforts and is the formal liaison between the community and the LSST Scheduler and Operations Simulation teams.

The LSST Science Advisory Committee (SAC) is charged with collecting and delivering various community input to the Project. Strategic and political issues about the LSST survey strategy should be communicated via the SAC (chair: Michael Strauss, strauss at astro.princeton.edu).

In addition to this call for white papers, the Observing Strategy white paper\footnote{A living document available at https://github.com/LSSTScienceCollaborations/ObservingStrategy} provides a coordinated mechanism for providing scientific input about survey strategy. LSST science collaborations are also official channels for communication with the LSST project --- a Data Management liaison is assigned to each Science Collaboration to answer specific questions about data products generated by the project.

An open, searchable resource for asking questions not addressed in this document is available on \href{http://community.lsst.org}{LSST Community}, in the Science category, SurveyStrategy subcategory. Team members will monitor and respond in a timely manner to questions posted there. Please go to \url{http://community.lsst.org}

There is a mailing list available (email: lsst-survey-strategy at lsstcorp.org) to contact the survey strategy team in case of specific 
questions and/or concerns. Messages posted to the mailing list are broadcasted to the survey strategy team and archived. 

Throughout the survey strategy design process there will be open community meetings. The first of these will be 
at the LSST All Hands Meeting 2018 in Tucson, AZ (August 13-17, 2018). 

Note that our teams cannot support individuals or groups wishing to run the Operations Simulator themselves. We will provide documentation on running OpSim and docker images (as well as the source code) will be made available, however we do not have resources to provide help desk facilities on this topic. 

\subsection{Additional Simulated Survey Strategies}

By the time this call for white papers is officially released, we anticipate that we will provide several more sample simulated surveys for the community to use as test cases. These modified survey strategies will include (approximately): 
\begin{itemize}
\item The baseline survey strategy, with the main survey having a 18,000 deg$^2$ footprint, the North Ecliptic Spur, South Celestial Pole, Galactic Plane and Deep Drilling minisurveys operating in the current example baseline survey strategy manner. 
\item A survey with a much larger main survey footprint (27,000 deg$^2$ -- defined by airmass limit $X<1.5$ and declination limits 
$-78<$ Dec $< +18$, and including only the Deep Drilling mini-survey (and no other mini surveys).
\item A survey strategy with `more visits': each visit being 20 seconds long with a single exposure per visit, and 40 second visits in the $u$ band (and probably another similar survey with exposures of 40 sec and 60 sec, respectively). 
\item A survey similar to the current baseline, with the Galactic Plane at the main survey cadence (and the northern tip of the galactic plane minisurvey removed).
\item A survey similar to the current baseline, but with additional Deep Drilling fields.
\item A survey similar to the current baseline, but with a modified cadence for Deep Drilling fields (ideally: observe in only 3 filters per night, but with a shorter gap between nights; rotating among the 3 filters used in each night).
\item Rolling cadence simulations in the main survey -- concentrating observations in bands of declination in some simulations, and in bands of R.A. in other simulations
\item A survey similar to the current baseline, but obtaining pairs of visits in different filters (vs. the same filter).
\item A survey similar to the current baseline, but only observing with single visits per night.
%\item A survey similar to the current baseline, but adding random ToO trigger events.
\end{itemize}

\end{document} 



\section{SAC recommendations} 

Aug 14 and Dec 8, 2017: 

- single call for deep drilling fields and mini-surveys
- reviewed by SAC 
- distribute widely (e.g., the AAS newsletter, presentations at AAS meetings, social media)
- make opsim4 outputs available well before the deadline (essentially when the call is issued) 
- the LSST Communications team should develop a strategy for getting the word out, using social media, 
      the AAS newsletter, targeted e-mailing, announcements at the AAS and other meetings, and so on.
- there should be a continuing effort to solicit new metrics (or ideas for them) from the community. 
- need to develop details for the review process (the decisions on observing strategy must be as objective as possible) 



Stubbs white papers:
- snaps or no snaps
- narrow-band filters
- twilight observing 



ZI: modified cadences:

1) Large Area
    Maximize the main survey area (``Pan-STARRS'', 27,400 deg$^2$):
    X<1.5, DecMin=$-78^\circ$ and DecMax = $+18^\circ$, 
    No mini surveys, but include DDFs   

2) same as baseline, but no more than 1 visit per night

3) Many Visits 
    20 sec visits with single snap, and 40 sec in the u band 
    40 sec visits with single snap, and 60 sec in the u band 

4) Pairs with the same vs. different filters 

5) Some variations of rolling cadence


Stretch: 

6) Many DDFs ?? 
    24 DDFs, 12 observed every night, with out-in replacement every 2 weeks 
    standard visit or deeper? 1 or more filters per night? 


