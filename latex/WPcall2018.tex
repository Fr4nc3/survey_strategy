\documentclass[DM,lsstdraft,toc,usenatbib]{lsstdoc}

% Package imports go here
\usepackage{amsmath}	% Advanced maths commands
\usepackage{amssymb}
\usepackage{gensymb}  % degree symbol 
\usepackage{natbib}  % bibliography
\usepackage{cprotect} 
% Local commands go here

%% Journal abbreviations
%\bibliographystyle{aasjournal}

\title[Call for LSST Cadence White Papers]{Call for White Papers for LSST Cadence Optimization} 

\author{\v{Z}eljko Ivezi\'{c}, Lynne Jones, Tiago Ribeiro, \\
                 the LSST Project Science Team, \\
                 and  the LSST Science Advisory Committee} 

\setDocRef{Document-XXX}
\date{\today}
\setDocRevision{v0.1}
\setDocStatus{draft}
\setDocAbstract{%
The LSST community is invited to play a key role in the refinement of LSST's Observing Strategy 
by submitting white papers that will describe proposed modifications of the current baseline
survey strategy, including both the main survey and the so-called ``deep drilling fields'' and mini surveys. 
}

% Change history defined here. Will be inserted into
% correct place with \maketitle
% OLDEST FIRST: VERSION, DATE, DESCRIPTION, OWNER NAME
\setDocChangeRecord{%
\addtohist{1}{2018-06-30}{First released version.}{\v{Z}eljko Ivezi\'{c}}
}

\begin{document}

% Create the title page
% Table of contents will be added automatically if "toc" class option
% is used.
\maketitle


\section{Introduction} 

The Large Synoptic Survey Telescope (LSST) will provide an unprecedented optical 
imaging dataset that will support investigations of our Solar System, Galaxy and Universe, 
across half the sky and over ten years of repeated observation. LSST observations will be
scheduled automatically, with the scheduling algorithm designed to address all science goals 
and maximize observing efficiency for given observing constraints. LSST is constructing a 
flexible scheduling system that can respond to the unexpected and be re-optimized. 
It has already been shown through simulated surveys that a basic implementation of LSST's 
10-year observing strategy can deliver on a wide range of science. 

Nevertheless, exactly how the LSST observations will be taken is not yet finalized and there
are a number of open optimization questions. Indeed, it is anticipated that the observing strategy 
will continue to be refined and optimized throughout operations. The main purpose of this 
call for white papers is to solicit detailed proposals from communities interested in LSST science
for specific modifications of the current baseline survey strategy, including both the main survey and 
the so-called ``deep drilling fields'' and mini surveys.


\subsection{LSST community and LSST observing strategy}

The LSST community is already playing a key role in the refinement of LSST's observing strategy 
by developing and analyzing metrics for quantifying the success of simulated surveys.
An open github community\footnote{
https://github.com/LSSTScienceCollaborations/ObservingStrategy}
is where this work is being assembled. The effects of relatively small changes to the LSST survey strategy
on the detailed performance of the anticipated science investigations 
is explored in a living dynamically-evolving community white paper (the first
version was published as arXiv:1708.04058 in August 2017). The main lessons 
learned from the first version of this paper are: 
\begin{enumerate} 
\item The LSST Project should implement, analyze and optimize the rolling cadence idea
(a non-uniform sampling in time designed to ``compress'' observations for better coverage
of variable phenomena on time scales of a few months, driven by supernovae, asteroids, and
short-timescale stellar variability), and 
\item The LSST Project should execute a systematic effort to further improve the ultimate
LSST survey strategy (e.g., sky coverage optimization, u band depth optimization, special 
surveys, Deep Drilling Fields). 
\end{enumerate} 

Through the end of construction and commissioning, this community Observing Strategy 
White Paper will remain a living document and the main vehicle for the community to broadly 
communicate to the LSST Project regarding observing strategies. The LSST Project Scientist will 
periodically synthesize and act on the results presented in this paper, with support from the 
Project Science Team, the Science Advisory Committee and the future Survey Strategy Committee.


\subsection{Motivation for this white paper call}

Guided by the community input summarized in the Observing Strategy white paper, and further 
advice from the Science Advisory Committee (SAC), the LSST Construction Project has decided to
solicit detailed technical proposals for specific modifications of the current baseline survey strategy.

As discussed in more detail in Appendix A, analysis to date indicates that the baseline 
survey strategy, while meeting the basic science requirements for the LSST survey, can be meaningfully 
improved (the baseline survey strategy is described in detail in Sections 1.1 and 2.3 in the Observing Strategy
white paper, arXiv:1708.04058). The LSST Science Requirements Document\footnote{See ls.st/srd} 
is intentionally vague on survey strategy details because it recognized that science evolves and that the 
initial, by now more than a decade old, survey strategy will have to be re-optimized closer to first 
light. With LSST first light expected in 2020, now is the time to undertake the final pre-commissioning
optimization of the LSST baseline observing strategy. We seek science-driven input for cadence 
properties such as per-bandpass imaging depth, the sky coverage, temporal coverage, observing
rules, etc., as summarized in Appendix A. Investigations of a limited number of such survey strategy 
modifications are reported in Chapter 2 from the Observing Strategy white paper (and discussed 
in various supplementary materials listed in Appendix C). 


\subsection{General guidelines} 

We solicit detailed proposals for specific modifications of the current baseline survey strategy, including 
both the main survey and the so-called ``deep drilling fields'' and mini surveys. There are no 
specific limitations on what kind of science programs will be considered, but please note that 
the primary four LSST science themes remain the cornerstones of the LSST survey and cannot 
be easily abandoned (the LSST Science Requirements Document states that ``the adopted observing 
strategy will not jeopardize the goals of any of the four main science themes''). 

Detailed proposals are also solicited for novel ideas, such as twilight observing (see \S~ref{}) and 
(hypothetical) narrow-bandpass surveys\footnote{LINK to white paper by Stubbs}, as well as synergies 
with other major surveys ({\it e.g.}, WFIRST, Euclid). 

At this time we are not soliciting proposals to optimize observations during the commissioning period.
A call for commissioning proposals will be issued once the start date of commissioning is known with adequate accuracy (1-2 months). 

Technical constraints imposed by the system and observing conditions are summarized in 
Appendix B. In cases that require more detail, or in case of specific questions not addressed in this 
document, please start a discussion at \href{http://community.lsst.org}{community.lsst.org}\footnote{\url{https://community.lsst.org/c/sci} XX finish complete link}.

The LSST Science Requirements Document states that ``the adopted baseline design assumes a 
nominal 10-year duration with about 90\% of the observing time allocated for the main LSST survey.'',
and further clarifies that ``The remaining 10\% of observing time will be used to obtain improved 
coverage of parameter space\dots''. While the detailed time allocation will eventually depend on currently unknown system
performance parameters, it is unlikely that the goals of the main survey could be met with a time allocation
significantly below 80\%. In other words, it is plausible that the time allocated to programs other
than the main survey could significantly exceed 10\% (perhaps by as much as a factor of two), but 
no firm commitments beyond this statement of plausibility can be made at this time. 

The data from any given specialized survey will be treated in exactly the same way as all LSST 
data: there is no special proprietary access for the proposers. Indeed, the final set of the so-called
deep-drilling fields and other mini-surveys may be based on an amalgam of ideas from different 
white papers; there will be no sense in which a given proposal must be accepted or rejected as-is.  


\subsection{Review process and timeline}

The deadline for submitting white papers is November 29, 2018. For submission instructions, 
please see the next section. The input from the submitted white papers will be used to design multiple
options in observing strategies and generate quantitative assessments to be used for survey strategy optimization.
These multiple strategies will address varying science drivers and will form a ``menu'' of possible survey strategies (e.g., a main 
survey with 18,000 deg$^2$ of sky coverage vs. sky coverage of 23,000 deg$^2$ to a
somewhat shallower depth). The performance evaluation criteria submitted as part of the white paper proposals
will be used to generate quantitative assessments to compare these strategies. 

Soon after the November 2018 submission deadline, members of the LSST Science Advisory Committee (SAC), 
with technical support from the Project\footnote{The Project will establish a Survey 
Strategy Committee to evaluate competing survey strategy proposals and to propose a general survey 
strategy for commissioning and operation. The committee will be comprised of both project and 
non-project personnel, with the SAC making recommendations for committee membership.}, 
will triage white papers and decide which meet the criteria of scientific excellence and 
technical feasibility for further analysis (including suggestions for combining 
proposals into single programs, and giving suggestions for maturation of the current notional 
extragalactic observing strategy). 

We anticipate that the resulting list of observing strategies that will be simulated and analyzed 
(the ``menu'' above) will be available by April 2019. Simulated survey outputs and Metric Analysis 
Framework (MAF\footnote{https://sims-maf.lsst.io}) analyses will become available by the end 
of 2019. 

An advisory report on these survey strategies will be prepared for the LSST SAC during early 2020, 
in a close collaboration between the Project and the Observing Strategy Github community and 
LSST Science Collaborations. The SAC will in turn advise the project on the specific survey strategy 
to be used at the start of LSST operations. In developing their recommendations to the Director, the SAC will be guided by selection 
criteria set by the Project Science Team ({\it e.g.}, restrictions based on technical criteria,
such as those discussed in Appendix B). The Director can further consult with the Project Science 
Team about the SAC survey strategy recommendations. A baseline simulation that reproduces the
adopted strategy, and its detailed performance analysis, will be published in 2021. 
The start of LSST operations is anticipated in 2022.

An overall aim of the Project and all stakeholders is to make this process transparent and to base 
all decisions on quantitative input and pre-defined criteria to the maximum extent possible. 
The Project will organize a dedicated session about this call for white papers, to further clarify 
details, exchange ideas, discuss simulated surveys, and coordinate teams that plan to submit white papers,
at the LSST 2018 All-hands meeting (Tucson, Aug 13-17). 


\section{White paper submission guidelines} 


\subsection{Who can submit a white paper?} 

All members of scientific community interested in LSST science can submit a white paper. 
We reiterate that the data from any given specialized survey will be treated exactly the same 
way as all LSST data: the proposers will have no proprietary access to it. There will be no 
formal ``acceptance'' of proposals; with the overall ranking priority advice provided to the 
Project by the Science Advisory Committee, the Project Team will implement a number of
different strategies that will be used as quantitative input (``a menu of options'') by the 
Science Advisory Committee when recommending the strategy to be used during the initial 
phase of LSST survey. 


\subsection{Requested input}

The current list of surveys for which input is requested are:
%
\begin{itemize}
\item the main Wide-Fast-Deep (WFD) survey,
\item the Deep Drilling (DD) mini-survey,
\item Northern Ecliptic Spur (NES) mini-survey, 
\item Galactic Plane (GP) mini-survey, and
\item South Celestial Pole (SCP) mini-survey.
\end{itemize}
%
Input on possible new mini-surveys to replace and/or enhance the current 
list of projects and, special programs (e.g. ToO) are also welcome.  

The main points of interests are:
%
\begin{itemize} 
\item a specific observing strategy to enable specific time domain science, 
	that is relatively agnostic to pointing (e.g., a science case enabled 
	by deep precise multi-color photometry). 
\item a specific pointing(s) that is (relatively) agnostic of the detailed observing 
	strategy (e.g., a science case enabled by deep precise multi-color 
	photometry) 
\item an integrated program with science that hinges on the pointing/detailed 
	observing strategy combination (e.g., search for variable stars in the 
	LMC/SMC) 
\end{itemize}  

% refer to an example of DDF in tex template below

It is 
important to keep in mind that the total time allocated to all the mini-surveys 
(including DD) shall not exceed $20\%$ of the allocable observing time.
Questions of
mini-surveys and DD fields are coupled at some level to
WFD: more time for the former means less for the latter,
and some of the design decisions for the latter affect the science
case for the former.  For example, how rolling cadence is done may
allow some variable and transient science to happen that would
otherwise be the focus of a deep drilling field, and changes in the
main survey footprint will affect the definition of a Galactic Plane
survey. 

For some special programs, e.g. ToO, it is important that reasonable
information is provided to enable proper simulations to be conducted, 
as well as estimation of total observing time allocation.

\subsection{TeX template for submission} 

A template and an example of the submission form, with instructions on
the required information, can be found on the survey strategy call for white
papers Github repository 
(\url{https://github.com/lsst-pst/survey_strategy}).

The submission process is going to be done through this repository,
and consists of;
%
\begin{enumerate}
\item Fork the repository on the PI's (or a selected collaborator)  Github account.
\item Clone the forked repository on your local machine.
\item Create a directory under proposal with the PI name as LASTNAME\_FIRSTNAME\_INSTITUTION. In case of duplicate directories, we may request changes during the review process later.
\item Copy the contents of the directory \texttt{proposal/template/} to the directory created on the last step.
\item Fill the latex template file with the proposal information. It is possible to make intermediate commits to keep track of the changes to the proposal and share it with collaborators.
\item Once the proposal is ready, make a Pull Request to the master branch of the main repository. 
\end{enumerate}


% ZI: it seems that submitting via pull requests to a github repo should be the easiest. 
% If undergrads can do it for their homeworks, our colleagues should be able to do it, too. 
% But whatever we do, we need to think about how to make it easy for us to handle them
% once submitted. 

% mention any restrictions on the length of the paper. 

% give an example as part of template, perhaps from the overview paper

% can we abstract the existing DDF strategies into this template form, too? 

%Explain how to submit by a pull request to Observing Strategy White Paper repo
% (a new dir? talk to Phil M.) 

\section{Proposal ranking criteria} 

The ultimate LSST observing strategy will aim to deliver a cutting-edge data set to enable
the four LSST's cornerstone scientific programs, while at the same time maximizing the 
science possible with specialized observing using about 10\% of the total observing time. 

We anticipate that the adopted observing strategy will be based on an amalgam of ideas from 
different white papers; therefore, there will be no formal ``acceptance'' of proposals. The
overall ranking priority advice provided to the Project by the Science Advisory Committee 
will be based on the following considerations: 
\begin{itemize}
\item {\bf Science} Importance and robustness of proposed science program, including 
           its match to the unique abilities of the LSST system, and its consistency with the 
           main four LSST science themes. 
\item {\bf Versatility} The ability of proposed dataset to maximally enable LSST’s diverse science objectives. 
          Functionally, this means that Solar System and Milky Way science will be prioritized for pointing selection,
          with Time Domain science likely driving the temporal sampling window, and extragalactic science driving 
          the sky coverage and coadded depth. Programs proposing datasets that are of interest to other astronomical 
          facilities (e.g., observable by other flagship facilities on ground and in space) will be ranked high. 
\item {\bf Efficiency} Observing efficiency (including the system safety considerations).  Deep-drilling field 
          programs should be feasible from the hardware and software point of view (see Appendix B) and should 
          come in under ``rule of thumb'' amount of total observing time ($<$1\%, e.g. 250-300 hours of time,
          including overhead). 
\end{itemize} 

As always, the science program properties such as importance and robustness are open
to interpretation. It is inevitable that some science drivers will be in conflict, and even
observing efficiency may not be an defined in absolute sense. The Project and the Science Advisory 
Committee will strive to make the proposal ranking process transparent to the maximum extent possible. 


\vskip 0.0in
\newpage
{\it Acknowledgments:} this document has greatly benefited from discussions between 
the LSST Project Science Team, the LSST Science Advisory Committee and Kem Cook, 
Phil Marshall, Steve Ridgway, Daniel Rothchild, Peter Yoachim and numerous other members 
of the LSST Science Collaborations. 

\appendix


\section{Examples of open cadence optimization questions} 

Quantitative optimization of the LSST observing strategy requires many 
detailed decisions to be made, often with only an indirect science justification,
or with conflicting science drivers.  The most significant open questions and associated tradeoffs are listed below
for the main survey and each mini survey. 

\subsection{The main Wide-Fast-Deep survey} 

The baseline cadence optimizes the amount of sky covered in any given night (subject to 
the constraint of observing at airmass less than 1.4 throughout), and allows the entire sky 
visible at any time of the year to be covered in about three nights. The cadence is designed 
to give uniform coverage at any given time, and to reach the survey goals for measuring 
stellar parallax and proper motion, and the number of visits (825 visits, summed over the 
six filters). In the baseline implementation, the main survey covers about 18,000 deg$^2$ of 
high Galactic latitude sky, and spends about 85\% of the available observing time. 

Open questions and optimization options associated with the main survey are as follows: 
\begin{itemize}
\item With the current declination boundaries at Dec = $-65^\circ$ and Dec = $+5^\circ$,
the main survey area includes about 19,000 deg$^\circ$ (without the Galactic plane 
confusion zone, see \ref{sec:GP}). These boundaries were set to optimize the number of
detected galaxies and galaxies useful for cosmological studies. These galaxy counts 
stay within 5-10\% from the current baseline values even with a much larger survey area. 
For example, Section 2.4 in the Observing Strategy white paper describes a cadence simulation 
that covers 27,400 deg$^2$ to about 0.15 mag shallower coadded depth than in baseline 
cadence (airmass limit is relaxed to 1.5 and declination boundaries are at Dec = $-78^\circ$ 
and Dec = $+18^\circ$, with the mean number of visits per field about 20\% smaller that
in baseline cadence). This tradeoff between the sky coverage and coadded depth is still
open to optimization and it is important to receive science-driven optimization arguments
from all science programs. 
\item The observing time allocation per band listed in the Science Requirements Document
(Table 24) is given only as an illustration. Further optimization of this allocation for the main 
survey, and different fractional allocations for mini surveys, are likely possible. 
\item A ``rolling cadence'' (as opposed to uniform temporal sampling) can provide enhanced
sampling rates over a part of the survey, or the entire survey for a designated time, at the
cost of reduced sampling rate the rest of the time (while maintaining the nominal total 
visit counts). While it is known that science programs such as supernovae, asteroids, and
short-timescale stellar variability would benefit from rolling cadence, detailed cadence
parameters have not been optimized yet (e.g., ``rolling'' in RA vs. Dec). 
\item Current baseline cadence obtains two visits per night (within 15-60 minutes) in 
order to enable easy linking of asteroid detections, and robust identification of rapid 
photometric transients. Whether the two visits on the same night should be obtained 
in the same filter or in different filters has not been decided yet (e.g., in the context
of photometric transients, same filters would provide a more accurate measurement
of the brightness change, while different filters would provide a color constraint). 
\item Current baseline cadence assumes that a visit is composed of two 15-second
exposures, the so-called snaps. While snaps enable search for very rapid variability,
and help with cosmic ray rejection, there are compelling arguments to abandon
them, with observing efficiency being the main argument. 
\end{itemize}


\subsection{``Deep Drilling'' fields} 

The Deep Drilling (DD) fields are single pointings that are observed in extended sequences. 
In the first call for white papers on cadence optimization, the Project has received 
8 white papers from the community\footnote{These white papers are available from 
https://project.lsst.org/content/whitepapers32012}. These proposals often include certain 
filter combinations to ensure that near-simultaneous color information is available for 
variable and transient objects. Science programs proposed in most DD proposals are well 
matched to the size of LSST field of view (9.6 deg$^2$). However, it is plausible that some
programs may require several fields. 

Four of the LSST DD fields have been selected and announced (Elias S1, 
XMM-LSS, Extended Chandra Deep Field-South, and COSMOS). It is guaranteed that they 
will be observed with deeper coverage and more frequent temporal sampling than the main 
survey fields, but details are still open. It is expected that there will be more DD fields 
selected for the final survey (a plausible but not prescriptive range is 5-10). 


\subsection{Galactic plane survey \label{sec:GP}}

The baseline main survey excludes observations at low Galactic latitudes, where the high 
stellar density leads to a confusion limit at much brighter magnitudes than those attained 
at high Galactic latitudes. Assuming median seeing, this confusion limit corresponds to a
source density of about 1-2 million per deg$^2$. The current boundary of this ``Galactic
confusion zone'' starts at $|b|=10^\circ$ towards $l=0^\circ$ and linearly drops to $b=0^\circ$
at $l=90^\circ$ and $l=270^\circ$. Along this boundary, the confusion limit is reached at a
depth of $i \sim 26$; therefore, the useful coadded depth is at least 1-2 magnitudes 
shallower than for the main survey. Within this boundary, the fraction of galaxies is only
a few percent and an assumption that all sources are stars works well. For example, 
DECAPS survey generated a catalog with 2 billion sources in the Southern Galactic Plane
to a depth of about $r=23$ (with seeing around 1 arcsecond; Schlafly et al. 2018, 
arXiv:1710.01309). 

As guidance, stellar count simulations with the TRILEGAL code (Girardi et al. 2005, 
arXiv:astro-ph/050404) show that to the depth of $r=27.5$ there are about 2 billion
stars in the main survey area, with another 5 billion stars in the Galactic confusion 
zone. Of the latter, about 3 billion are brighter than $r=24.5$.  

The current strawman implementation of the Galactic confusion zone coverage allocates 
30 observations in each of the six filters. Detailed optimization of this strategy has not 
been done yet. In particular, science-driven input is needed for both ``static science''
programs (e.g., The Blanco DECam Bulge Survey, BDBS Collaboration) and  time domain
surveys (e.g., Gould 2013, arXiv:1304.3455). 

The footprint in the current baseline cadence extends to far north along the Galactic
plane, to the region that can only be observed at relatively large airmass from the LSST
site at Cerro Pach\'on ($X>1.4$ at Dec=$+15^\circ$). Originally, this extension was designed 
to extend longitudinal coverage of the Galactic plane with Galactic structure studies in mind. 
With the advent of other surveys (e.g., Pan-STARRS and DECAPS), the reasons for obtaining 
these less efficient observations (due to unavoidable high airmass) are less compelling. 
Unless a strong case is made in submitted white papers, the Project is likely to limit the 
coverage of the Galactic plane to Dec=$<+5^\circ$. 


\subsection{Southern Celestial pole mini survey}

The airmass limit of 1.4 adopted for the main survey restricts observations to $Dec > -75^\circ$,
thus missing large fraction of both the Magellanic Clouds. To allow coverage of the Large and 
Small Magellanic Clouds, baseline cadence uses relaxed limits on airmass and seeing for the 
700 deg$^2$ region around the South Celestial Pole, but with fewer observations that for the
main survey. 

Detailed optimization of this strategy has not been done yet. Given recent informative observations 
obtained by the SMASH survey (Nidever et al. 2017, arXiv:1701.00502), as well as calibration 
and legacy aspects of this mini survey, a white paper with more detailed cadence prescriptions
would greatly with further cadence optimization and help retain this mini survey. 


\subsection{Northern Ecliptic spur mini survey}

The universal cadence provides most of LSST’s power for detecting Near Earth Objects (NEO) and 
Kuiper Belt Objects (KBOs) and naturally incorporates the southern half of the ecliptic within its 
18,000 deg$^2$ sky area. Additional coverage of a crescent within 10 degrees of the Northern ecliptic 
plane would sample the full azimuthal distribution of TNOs, crucial for understanding the different 
dynamical families in which they fall, and would improve the light curve sampling and completeness
of asteroid populations in the inner Solar System. The baseline cadence covers this region using the 
$r$ and $i$ filters only, along with more relaxed limits on airmass and seeing. A more detailed 
and robust science justification addressing both outer Solar System (e.g., TNOs) and inner Solar
System (e.g., main-belt and NEO asteroids) populations is needed to retain this mini survey. 



\subsection{Twilight survey} 

FINISH ME! 

The short read-out time enables taking short-exposure images during twilight time that would otherwise go unused. 
Assuming exposure time of 1 second (the current stretch goal from the LSST Science Requirements Document; the
design value is 5 second), 


, together with short exposures, 


The implementation of this would simply entail taking short-exposure images during twilight time that would otherwise go unused. 


From Section 10.3 in OSWP: 

The current LSST requirements stipulate a minimum exposure time of 5 seconds, with an expected default exposure time of 15 seconds. This document advocates for decreasing the minimum expo- sure time requirement from 5 to 0.1 seconds. This would increase the dynamic range for bright sources (compared to the default 15 sec time) by about 5 magnitudes, to a total of 13 astronomical magnitudes (where dynamic range is the difference between the brightest unsaturated source and the faintest point source detectable at 5 sigma). This is a large factor, and would enable a wide range of science goals,

One interesting aspect of this is that it would allow us to operate the LSST system during twilight times that would otherwise saturate the array due to background sky brightness. This would allow a number of the goals described below to be carried out without impacting the primary survey by conducting observations during twilight sky conditions that would saturate the array at longer exposure times.


A Bright Star Survey for Galactic Science.

It is vitally important that we obtain these nearby-SN light curves on the same photometric system, reduced with the same data reduction pipeline, as the distant sample. This means we really must 
We stress that this twilight SN followup campaign can be accomplished without impacting the main survey, during the roughly 20 minutes per night of twilight that would otherwise unusable at the default exposure time. 

x
Copy relevant info from Stubbs document. 

twilight observing?  ref to Stubbs writeup and Sec 10.2.1 in OSWP: 

NEOs on very Earth-like orbits are relatively unlikely to come to opposition, and therefore are 
relatively unlikely to appear in data obtained in the wide-fast-deep survey. These objects are 
particularly interesting since, having very Earth-like orbits, they are the most likely objects to
be Earth impactors. These objects are most likely to be detected in a twilight survey that looks 
at the ``sweetspot'' -- a location at around 60$\circ$ Solar elongation that is only visible at 
twilight. Because these sweetspot fields are only visible for 30–60 twilight minutes each night, 
a special cadence is required to find and link these objects to determine their orbits. These 
observations would be best carried out in the $z$ filter (because the observations are made in 
twilight, when the sky is still relatively bright). 

10.3 Short Exposure Surveying to increase dynamic range by 5 mag with bright sources (to $r$ = 11-12) 




\section{Cadence constraints imposed by the LSST system} 


\subsection{Hardware constraints}


Telescope altitude limit, the zenith exclusion zone 


Per LSST Document SPT-494, the constraints on the filter exchange strategy are: 

For planning observations and in-dome calibration exposures, there is interest in the relevant engineering constraints on filter exchanges, beyond what is captured in requirements. As the system is not yet completely built and characterized, the following represents our current understanding, based on the design and on engineering judgement. As such, some of the details should be considered preliminary and subject to change. Expanded ranges could be possible if there are strong scientific motivations along with sufficient resources during operations.

The filter change mechanism is designed to undergo a total of 100,000 changes over its lifetime. Each filter is designed to support up to 30,000 changes over its lifetime.

A maintenance cycle is anticipated, and this would nominally occur after 10,000 changes or one year, whichever is reached first. The actual need will be informed by experience during Integration \& Test and commissioning.

During a given observing night, the system could support as many changes involving the 5 filters loaded in the carousel as desired, without any practical limitation beyond the two-minute change interval (which consists of 90 seconds for the exchange plus up to 30 seconds to put the camera into the required orientation). 

Filter loader operations (swapping a filter in the carousel) will be done during daytime. The system is designed for 3000 loads over its lifetime. 




\subsection{Software constraints} 

Double check DMTN-065

The Project will not take formal responsibility for specialized data reduction algorithms 
needed to process data, including that taken in ``non-standard'' modes; 
   
Refer to Melissa's doc on Special Programs 

Mention crowded fields (and perhaps deblending?), document from Mario. 



\subsection{Observing efficiency constraints and  ``cadence scaling laws''}

The LSST Science Requirements Document  ``...assumes a nominal 10-year duration with about 90\% 
of the observing time allocated for the main LSST survey.'', and thus 10\% of observing time is left for 
all other programs. However, if the system will perform better than expected, or if science priorities 
will change over time, it is conceivable that 90\% could be modified and become as low as perhaps 80\%, 
with the observing time for other programs thus doubled. At this time, details are TBD but the Project
is developing flexible scheduling procedures to enable such modifications. 

Weather uncertainty is ~10\% and we still have not built the system 

Minimum Exposure time: Science Requirements Document stretch goal is 1s; design spec is 5s.
Short exposures might have problems with irregular PSFs and will have a lower efficiency due to
finite read-out time (2 sec). Exposures much longer than standard 30 sec will cause fast asteroids
to be trailed. In dark time, the u band exposures are not background limited with the standard
exposure time (see Table 2 and related discussions in the LSST overview paper). 

Read-out time 

Slew time 

Standard exposure sequence: 2x15 sec 


\subsection{Limiting depth and uncertainty estimates,  and ``cadence scaling laws''} 

How to estimate limiting imaging depth for a given exposure time and other observing parameters
is discussed in Section 3.2 in the LSST Overview paper (see \ref{sec:pubs}). Tradeoffs between 
exposure time per visit, single-visit depth, the mean revisit time, and the total number of visits,
as well as justification for the adopted standard exposure time of 30 sec, are discussed in Section 
2.2 from the same paper. The improvement in measurement uncertainties as the surveys progresses
(as a function of time, $t$) can be approximately summarized as follows. 

The coadded depth (the 5$\sigma$ depth for point sources), $m_5^{\rm coadd}$, scales 
with time as (see eq.~6 in the overview paper)  
\begin{equation} 
         m_5^{\rm coadd}  = m_5^{\rm coadd, Final}  + 1.25 \, \log_{10}\left({t \over 10 \, {\rm yrs}}\right) 
\end{equation} 
where $m_5^{\rm coadd, Final}$ is the target depth achieved with 10-year survey (with
airmass and other losses taken into account, $m_5^{\rm coadd, Final}=27.2$ for the $r$ band). 

The photometric errors (inverse signal-to-noise ratio) at the faint limit of the so-called 
``gold'' galaxy sample (4 billion galaxies with $i<25.3$ which will be used for cosmological
programs, see Section 3.7.2 in the LSST Science Book), is computed from (see eq. 5 and Table 1 
in the overview paper):
\begin{equation} 
                \sigma_{i=25} = 0.04 \, \left({t \over 10 \, {\rm yrs}}\right)^{-1/2} {\rm mag.}
\end{equation}

The volume of the 5-dimensional color space per source with $i=25$,  which controls the ability 
to classify sources using colors (including photometric redshift estimates for galaxies and star/quasar
separation, for example) is computed assuming uncorrelated color errors, as proportional
to $\sigma^5_{i=25}$, and normalized by the value corresponding to 10-year survey. 

The trigonometric parallax accuracy for a point source with $r$=24 (see section 3.3.3 in the 
overview paper) scales with time as 
\begin{equation}
        \sigma_\pi = 3.0 \,  \left({t \over 10 \, {\rm yrs}}\right)^{-1/2}  \,\,  {\rm mas.} 
\end{equation}

The proper motion accuracy for a point source with $r$=24 (see section 3.2.3 in the overview paper)
scales with time as 
\begin{equation}
        \sigma_\mu = 1.0 \,  \left({t \over 10 \, {\rm yrs}}\right)^{-3/2}   \,\, {\rm mas/yr.} 
\end{equation}
Note the very strong dependence of  $\sigma_\mu$ on time ($t^{-1/2}$ comes from the
increase in the square root of the number of visits, analogously to $\sigma_\pi$, and 
an additional $t^{-1}$ from the linear increase in temporal baseline).  In both expressions,
the number of visits is assumed proportional to time, with a value of 825 corresponding to the 
main deep-wide-fast 10-year survey. 

The behavior of these quantities as a function of time is summarized in Table 3. While 
the coadded depth and $\sigma$($i$=25) rapidly improve during the first few years, 
several important quantities continue to show marked improvement between the survey 
years 8 and 10: most notably, the color volume per source for faint sources ($i=25$) 
shrinks by a factor of 1.7.  Substantial improvement is also seen for proper motions, 
with errors larger by 40\%, after 8 years than at the end of the 10-year survey.  

\begin{table}
\caption{Various science metrics as functions of survey duration.}
\begin{tabular}{|l|r|r|r|r|r|r|}
\hline     
          Quantity                          &     Year 1   &    Y3  &     Y5  &     Y8   &     Year 10   \\
\hline  
    $r_5$ coadd$^a$                   &       26.0    &      26.5   &      26.8    &      27.1    &          27.2     \\
    $\sigma$($i$=25)$^b$         &     0.12    &     0.07    &      0.06    &    0.05      &        0.04        \\     
    color vol.$^c$                        &       316     &       20     &        6      &    1.7        &           1       \\
     \# of visits$^d$                    &          83     &     248     &      412     &    660      &          825      \\  
    $\sigma_\pi$ ($r$=24)$^e$   &        9.5     &      5.5     &        4.2    &     3.3       &          3.0      \\ 
    $\sigma_\mu$ ($r$=24) $^f$  &  32   &      6.1    &     2.8   &     1.4   &     1.0     \\
\hline                         
\end{tabular}
\\ \vskip 0.05in
$^a$ The coadded depth in the $r$ band (AB, 5$\sigma$; point sources).  \\
$^b$ The photometric error for a point source with $i=25$. \\
$^c$ The volume of the 5-dimensional color space, normalized by the final value. \\
$^d$ The number of visits per sky position (summed over all bands). \\
$^e$ The trigonometric parallax accuracy for a point source with $r$=24 (milliarcsec). \\ 
$^f$  The proper motion accuracy for a point source with $r$=24 (milliarcsec/yr).  \\
%\vskip 0.2in          
\end{table}








\section{Supplementary materials} 
\label{append:supplemental}

\subsection{Useful publications and documents \label{sec:pubs}}

The \href{https://www.lsst.org/content/lsst-science-drivers-reference-design-and-anticipated-data-products}{LSST Overview paper} provides a short summary of the four primary science drivers, as well as the expected performance of LSST in terms of throughputs, and calibration. 
It also discusses high-level survey constraints and tradeoffs.  Available as \url{http://ls.st/pif}

The \href{https://github.com/LSSTScienceCollaborations/ObservingStrategy}{Observing Strategy White Paper}  (OSWP) is a community-driven paper describing a wide variety of science cases and their implications for survey strategy. This paper is primarily aimed at helping define the main (90\%) WideFastDeep survey. Available as \url{http://ls.st/3y1}

The \href{http:/ls.st/srd}{LSST Science Requirements Document} (SRD) describes the official requirements for LSST science deliverables. Section 3.4 is the most relevant for survey strategy, although other sections are relevant for telescope and camera performance such as throughputs and readout time. Available as \url{http://ls.st/srd}

The \href{http://ls.st/dpdd}{LSST Data Products Definition Document} (DPDD) describes the data products that LSST will provide, with some high-level background on how they will be produced. If you want to know what will be contained in various catalogs, this is a good place to look. Available as \url{http://ls.st/dpdd}

The \href{http://ls.st/ldm-151}{LSST Data Management Science Pipelines Design} (LDM-151) document describes the LSST data management processing pipelines. This provides details of how and when images will be processed and catalogs will be generated, including information on the algorithms used in each processing stage. If you want to know more about the details of a value in an output catalog and how it will be calculated, this is the place to look. Available as \url{http://ls.st/ldm-151}

%The \href{http://ls.st/lse-61}{LSST Data Management System Requirements} (DMSR) document details the official requirements for LSST's data management processing. This is a higher level of detail than the DPDD on the characteristics and specifications of individual data products but does not describe how these data products are created. \url{http://ls.st/lse-61}

The \href{https://github.com/lsst-pst/survey_strategy/blob/master/db/baseline-doc/baseline.pdf}{baseline simulated survey} document describes the new features enabled in Opsim v4, as well as characteristics of the updated baseline simulated survey. 
{\bf XXX: LINK WILL ADDED HERE!}


\subsection{Useful websites and slide collections}

{\it Note that these websites are still in development.}

Documentation about MAF, including a high-level overview and descriptions of current standard metric analyses, is available at \url{http://sims-maf.lsst.io}. 
The outputs of MAF analyses for the new baseline survey, as well as runs demonstrating potential options for mini surveys and Deep 
Drilling fields (a subset of the runs described in Chapter 2 of the OSWP) are available \href{http://astro-lsst-01.astro.washington.edu:8080}{online} at \url{http://astro-lsst-01.astro.washington.edu:8080}. 

Documentation about OpSim (SOCS and Scheduler), including a high-level overview and description of scheduling options, is available at \url{http://sims-opsim.lsst.io}.

A short description of the current Deep Drilling fields and links to further materials (including white papers submitted in response to the 2011 call for input on the DD strategy) are available on the LSST website at \href{https://www.lsst.org/scientists/survey-design/ddf}{http://ls.st/57q}. Additional posts on LSST Community can be found by searching for \href{https://community.lsst.org/search?q=deep%20drilling}{`deep drilling'}. 

An open, searchable resource for asking questions not addressed in this document is available on \href{http://community.lsst.org}LSST Community, in the Science category, SurveyStrategy subcategory. Team members will monitor and respond in a timely manner to questions posted there.  Please go to \url{http://community.lsst.org}

Additional information is available in the following presentations:
\begin{itemize}
\item ``Overview of the LSST Observing Strategy'' (Nov 16, 2015): \url{http://ls.st/4yh}
\item ``The LSST Deep-Drilling Fields: White Papers and Science Council Selected Fields'' (Aug 15, 2016): \url{http://ls.st/wzy}
\item ``Observing Strategy White Paper Status Report'' (Mar 5, 2017): \url{http://ls.st/zj2}
\item ``LSST Plans for Cadence Optimization'' (May 30, 2017): \url{http://ls.st/ot2}
\item ``Special Programs'' (Aug 15, 2017): \url{http://ls.st/10o}
\end{itemize}.


\subsection{Communication about the LSST survey strategy} 

The Project Scientist (\v{Z}eljko Ivezi\'{c}, e-mail: ivezic at astro.washington.edu) is formally responsible for survey strategy optimization efforts and is the formal liaison between the community and the LSST Scheduler and Operations Simulation teams.

The LSST Science Advisory Committee (SAC) is charged with collecting and delivering various community input to the Project. Strategic and political issues about the LSST survey strategy should be communicated via the SAC (chair: Michael Strauss, strauss at astro.princeton.edu).

In addition to this call for white papers, the Observing Strategy white paper\footnote{A living document available at https://github.com/LSSTScienceCollaborations/ObservingStrategy} provides a coordinated mechanism for providing scientific input about survey strategy. LSST science collaborations are also official channels for communication with the LSST project --- a Data Management liaison is assigned to each Science Collaboration to answer specific questions about data products generated by the project.

There will be public (open and archived) discussions with the survey strategy team, as well as LSST Data Management and LSST Education and Public Outreach teams, on \href{http://community.lsst.org}{LSST Community} (\url{http://community.lsst.org}). 

Throughput the survey strategy design process there will be open meetings. The first of these will be at the LSST All Hands Meeting 2018 in Tucson, AZ (August 13-17, 2018). 

\end{document} 



\section{SAC recommendations} 

Aug 14 and Dec 8, 2017: 

- single call for deep drilling fields and mini-surveys
- reviewed by SAC 
- distribute widely (e.g., the AAS newsletter, presentations at AAS meetings, social media)
- make opsim4 outputs available well before the deadline (essentially when the call is issued) 
- the LSST Communications team should develop a strategy for getting the word out, using social media, 
      the AAS newsletter, targeted e-mailing, announcements at the AAS and other meetings, and so on.
- there should be a continuing effort to solicit new metrics (or ideas for them) from the community. 
- need to develop details for the review proces (the decisions on observing strategy must be as objective as possible) 



ZI: modified cadences:

1) Large Area
    Maximize the main survey area (``Pan-STARRS'', 27,400 deg$^2$):
    X<1.5, DecMin=$-78^\circ$ and DecMax = $+18^\circ$, 
    No mini surveys, but yes for DDFs   

2) Many Visits 
    20 sec visits with single snap, and 40 sec in the u band 

Stretch: 

3) Many DDFs ?? 
    24 DDFs, 12 observed every night, with out-in replacement every 2 weeks 
    standard visit or deeper? 1 or more filters per night? 




Stubbs white papers:
- snaps or no snaps
- narrow-band filters
- twilight observing 

